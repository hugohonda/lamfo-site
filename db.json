{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/clean-blog/source/css/article.styl","path":"css/article.styl","modified":1,"renderable":1},{"_id":"themes/clean-blog/source/css/mixins.styl","path":"css/mixins.styl","modified":1,"renderable":1},{"_id":"themes/clean-blog/source/css/base.styl","path":"css/base.styl","modified":1,"renderable":1},{"_id":"themes/clean-blog/source/css/style.styl","path":"css/style.styl","modified":1,"renderable":1},{"_id":"themes/clean-blog/source/css/variables.styl","path":"css/variables.styl","modified":1,"renderable":1},{"_id":"themes/clean-blog/source/img/favicon.ico","path":"img/favicon.ico","modified":1,"renderable":1},{"_id":"themes/clean-blog/source/img/ggplot.png","path":"img/ggplot.png","modified":1,"renderable":1},{"_id":"themes/clean-blog/source/img/chunk-8.png","path":"img/chunk-8.png","modified":1,"renderable":1},{"_id":"themes/clean-blog/source/img/home-bg.jpg","path":"img/home-bg.jpg","modified":1,"renderable":1},{"_id":"themes/clean-blog/source/img/0026.png","path":"img/0026.png","modified":1,"renderable":1},{"_id":"themes/clean-blog/source/img/debug.log","path":"img/debug.log","modified":1,"renderable":1}],"Cache":[{"_id":"themes/clean-blog/LICENSE","hash":"8726b416df4f067cff579e859f05c4b594b8be09","modified":1489799069441},{"_id":"themes/clean-blog/README.md","hash":"c5c7b0fd01aa229304e7b00697517aaca51de577","modified":1489799069441},{"_id":"themes/clean-blog/_config.yml","hash":"a4154e14372bf7f4cdd99615704d9942c2290c1a","modified":1493654122339},{"_id":"source/_drafts/teste-R.md","hash":"1c81ce7f83b40e1d73ad3b8cba9c85f98a23cda4","modified":1493519435092},{"_id":"source/_posts/Um-Olhar-Descontraido-Sobre-o-Dilema-Vies-Variancia.md","hash":"52f6110b72eb8aa7d54e7f6e69a0e18ca583c897","modified":1493565152878},{"_id":"source/_posts/A-Casual-Look-at-the-Bias-Variance-Dilemma.md","hash":"96baad84ca0e0a41b49f28cf9778eb86893873f1","modified":1493565522148},{"_id":"themes/clean-blog/.git/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1489799069425},{"_id":"themes/clean-blog/.git/config","hash":"ce343df4c223954b137ec3cc8a94736a4e2c6cd5","modified":1489799069425},{"_id":"themes/clean-blog/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1489799066445},{"_id":"themes/clean-blog/.git/index","hash":"40ade50e81665033019577c978a864141e0ccb94","modified":1493591000551},{"_id":"themes/clean-blog/.git/packed-refs","hash":"1dadbd4fdd53bbb7038fa2c7b3c71cd028c4ead4","modified":1489799069425},{"_id":"themes/clean-blog/languages/de.yml","hash":"424a9c1e6ab69334d7873f6574da02ca960aa572","modified":1489799069441},{"_id":"themes/clean-blog/languages/default.yml","hash":"97326c9e6518d9f379778178b3b8f9a58434725d","modified":1489799069441},{"_id":"themes/clean-blog/languages/en.yml","hash":"97326c9e6518d9f379778178b3b8f9a58434725d","modified":1489799069441},{"_id":"themes/clean-blog/languages/es.yml","hash":"cb4eeca0ed3768a77e0cd216300f2b2549628b1b","modified":1489799069441},{"_id":"themes/clean-blog/languages/fr.yml","hash":"e9e6f7cb362ebb7997f11027498a2748fe3bac95","modified":1489799069441},{"_id":"themes/clean-blog/languages/no.yml","hash":"8ca475a3b4f8efe6603030f0013aae39668230e1","modified":1489799069441},{"_id":"themes/clean-blog/languages/pl.yml","hash":"de7eb5850ae65ba7638e907c805fea90617a988c","modified":1489799069441},{"_id":"themes/clean-blog/languages/pt.yml","hash":"1d0c3689eb32fe13f37f8f6f303af7624ebfbaf0","modified":1489799069441},{"_id":"themes/clean-blog/languages/ru.yml","hash":"42df7afeb7a35dc46d272b7f4fb880a9d9ebcaa5","modified":1489799069441},{"_id":"themes/clean-blog/languages/zh-CN.yml","hash":"7bfcb0b8e97d7e5edcfca8ab26d55d9da2573c1c","modified":1489799069441},{"_id":"themes/clean-blog/languages/zh-TW.yml","hash":"9acac6cc4f8002c3fa53ff69fb8cf66c915bd016","modified":1489799069441},{"_id":"themes/clean-blog/layout/archive.ejs","hash":"ad0da72df13ce3566985bb390c2c9a9352cf4f07","modified":1489799069441},{"_id":"themes/clean-blog/layout/index.ejs","hash":"87995288ca6f95a04add641727aedd3f6afa55eb","modified":1489799069441},{"_id":"themes/clean-blog/layout/layout.ejs","hash":"da2f9018047924ddaf376aee5996c7ddc06cebc1","modified":1493587939226},{"_id":"themes/clean-blog/layout/page.ejs","hash":"38382e9bbeb6b8d2eafbd53fff2984111f524c1a","modified":1489799069441},{"_id":"themes/clean-blog/layout/post.ejs","hash":"38382e9bbeb6b8d2eafbd53fff2984111f524c1a","modified":1489799069441},{"_id":"themes/clean-blog/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1489799066445},{"_id":"themes/clean-blog/.git/hooks/applypatch-msg.sample","hash":"4de88eb95a5e93fd27e78b5fb3b5231a8d8917dd","modified":1489799066445},{"_id":"themes/clean-blog/.git/hooks/pre-applypatch.sample","hash":"f208287c1a92525de9f5462e905a9d31de1e2d75","modified":1489799066445},{"_id":"themes/clean-blog/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1489799066445},{"_id":"themes/clean-blog/.git/hooks/pre-push.sample","hash":"5c8518bfd1d1d3d2c1a7194994c0a16d8a313a41","modified":1489799066445},{"_id":"themes/clean-blog/.git/hooks/pre-commit.sample","hash":"36aed8976dcc08b5076844f0ec645b18bc37758f","modified":1489799066445},{"_id":"themes/clean-blog/.git/hooks/prepare-commit-msg.sample","hash":"2b6275eda365cad50d167fe3a387c9bc9fedd54f","modified":1489799066445},{"_id":"themes/clean-blog/.git/hooks/update.sample","hash":"e729cd61b27c128951d139de8e7c63d1a3758dde","modified":1489799066445},{"_id":"themes/clean-blog/.git/hooks/pre-rebase.sample","hash":"18be3eb275c1decd3614e139f5a311b75f1b0ab8","modified":1489799066445},{"_id":"themes/clean-blog/.git/info/exclude","hash":"c879df015d97615050afa7b9641e3352a1e701ac","modified":1489799066445},{"_id":"themes/clean-blog/.git/logs/HEAD","hash":"912e7aeb4e546b9c0c6156cfa799cd68010746a2","modified":1489799069425},{"_id":"themes/clean-blog/layout/_partial/after-footer.ejs","hash":"80970a6cfbf9b1abe0c472636b321a9be08fdc43","modified":1489799069441},{"_id":"themes/clean-blog/layout/_partial/article-archive.ejs","hash":"3d8d98c6545b8332a6d6ed4f8b00327df03ea945","modified":1489799069441},{"_id":"themes/clean-blog/layout/_partial/article-categories.ejs","hash":"5a0bf5a20f670621d8013c9b9d7976b45c8aa80f","modified":1489799069441},{"_id":"themes/clean-blog/layout/_partial/article-index.ejs","hash":"e433df4e245e2d4c628052c6e59966563542d94d","modified":1489799069441},{"_id":"themes/clean-blog/layout/_partial/article-full.ejs","hash":"8d63ce240bbcc850b5d438d1f45ad9441ac1c9cc","modified":1493587246185},{"_id":"themes/clean-blog/layout/_partial/article-tags.ejs","hash":"6136434be09056c1466149cecb3cc2e80d107999","modified":1489799069441},{"_id":"themes/clean-blog/layout/_partial/comments.ejs","hash":"3fedb75436439d1d6979b7e4d20d48a593e12be4","modified":1489799069441},{"_id":"themes/clean-blog/layout/_partial/gallery.ejs","hash":"21e4f28909f4a79ff7d9f10bdfef6a8cb11632bf","modified":1489799069441},{"_id":"themes/clean-blog/layout/_partial/footer.ejs","hash":"d252fb1a41890e6481bb054f9cc4ceec3c0b0ed9","modified":1489799069441},{"_id":"themes/clean-blog/layout/_partial/google-analytics.ejs","hash":"4e6e8de9becea5a1636a4dcadcf7a10c06e2426e","modified":1489799069441},{"_id":"themes/clean-blog/layout/_partial/menu.ejs","hash":"ba299316400499e9ede154e9627cafb7ce411888","modified":1489799069441},{"_id":"themes/clean-blog/layout/_partial/head.ejs","hash":"3a7eb32f2cc540746c9e11010a4513b832743d1e","modified":1489799069441},{"_id":"themes/clean-blog/layout/_partial/pagination.ejs","hash":"557d6bb069a1d48af49ae912994653f44b32a570","modified":1489799069441},{"_id":"themes/clean-blog/source/css/article.styl","hash":"f5294d7a3d6127fcb287de3ff0c12aebb1766c7b","modified":1489799069441},{"_id":"themes/clean-blog/source/css/mixins.styl","hash":"892f55e8a71f2e23a52e48e217dad3303bbad913","modified":1489799069441},{"_id":"themes/clean-blog/source/css/base.styl","hash":"f0a6fcf58fe515e1359acde0ed34081f580ec7a3","modified":1489799069441},{"_id":"themes/clean-blog/source/css/style.styl","hash":"c40dc495a41007d21c59f342ee42b2d31d7b5ff4","modified":1489799069441},{"_id":"themes/clean-blog/source/css/variables.styl","hash":"cd82df5ca8dfbcfec12d833f01adfac00878e835","modified":1489799069441},{"_id":"themes/clean-blog/source/img/favicon.ico","hash":"bd8b366560b8b47d3d6b5113b40986852f8b03b9","modified":1489812236783},{"_id":"themes/clean-blog/source/img/ggplot.png","hash":"d7e8d4893f5bd4ef743491cd08ad7f78dca78272","modified":1489802560684},{"_id":"themes/clean-blog/source/img/chunk-8.png","hash":"303deac0f695bce02051a404b078fdb37b98c1fc","modified":1493564720110},{"_id":"themes/clean-blog/.git/objects/pack/pack-150961354dcaf41617990f9a9d18fb969ec0b9fb.idx","hash":"32e5daf443ca079417d364b3ef3a4144baae432b","modified":1489799069297},{"_id":"themes/clean-blog/.git/refs/heads/master","hash":"cce37529c01e70f25e6266bf6fb91c4c88b2f9fb","modified":1489799069425},{"_id":"themes/clean-blog/.git/logs/refs/heads/master","hash":"912e7aeb4e546b9c0c6156cfa799cd68010746a2","modified":1489799069425},{"_id":"themes/clean-blog/.git/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1489799069425},{"_id":"themes/clean-blog/source/img/home-bg.jpg","hash":"c7216008f8ce59839a98ec91d1824c6e99b9d382","modified":1489798160073},{"_id":"themes/clean-blog/.git/logs/refs/remotes/origin/HEAD","hash":"912e7aeb4e546b9c0c6156cfa799cd68010746a2","modified":1489799069425},{"_id":"themes/clean-blog/source/img/0026.png","hash":"a159613223b10b92b8be4f9dbfe869cf00adf233","modified":1492814611000},{"_id":"themes/clean-blog/.git/objects/pack/pack-150961354dcaf41617990f9a9d18fb969ec0b9fb.pack","hash":"4cc90aed47a7c34d707952de5396981e230bfff1","modified":1489799069297},{"_id":"themes/clean-blog/source/img/debug.log","hash":"b359d270fa6a909eb82fa163d7165892bf4a653e","modified":1489802743040},{"_id":"public/img/ggplot.png","hash":"ae042077b42237f04d87a9f966349773b147f1b6","modified":1493654167993},{"_id":"public/img/chunk-8.png","hash":"5d7d5e3d521fb62b16e8f4de41f4402047a3b233","modified":1493654168053},{"_id":"public/img/home-bg.jpg","hash":"63d3f17cea8d14960f3dbe3ac9a9603e2aedb654","modified":1493654168079},{"_id":"public/img/0026.png","hash":"a4394609179aa403d4d63421453dc5854d23fd26","modified":1493654168926},{"_id":"public/sitemap.xml","hash":"215a3a4955781bf64fa8141e91f264b03c2bc35c","modified":1493654168926},{"_id":"public/2017/04/29/A-Casual-Look-at-the-Bias-Variance-Dilemma/index.html","hash":"6f8646ab4697582807dc9d9cc3406e10ce87c0a6","modified":1493654168940},{"_id":"public/2017/04/29/Um-Olhar-Descontraido-Sobre-o-Dilema-Vies-Variancia/index.html","hash":"6f35f04c150d42e845c66d077505133c402dd6c8","modified":1493654168940},{"_id":"public/archives/index.html","hash":"193d36790e00fec7485f56134aab00a2428fa73b","modified":1493654168940},{"_id":"public/archives/2017/index.html","hash":"c3b308c76951c06194905919e7b6917925f029ac","modified":1493654168941},{"_id":"public/archives/2017/04/index.html","hash":"0e89fef4869c638462268dfcefe2ffa7422caf06","modified":1493654168941},{"_id":"public/en/2017/04/29/Um-Olhar-Descontraido-Sobre-o-Dilema-Vies-Variancia/index.html","hash":"a8117f3c91a16e7458589d15888569b2c3cfec3d","modified":1493654168941},{"_id":"public/en/2017/04/29/A-Casual-Look-at-the-Bias-Variance-Dilemma/index.html","hash":"6f8646ab4697582807dc9d9cc3406e10ce87c0a6","modified":1493654168941},{"_id":"public/en/archives/index.html","hash":"898c6a5cb50c3cd2e1e01b4eb5ac875e814969a6","modified":1493654168941},{"_id":"public/en/archives/2017/index.html","hash":"3761ac3b051d71c91625e3ef2da4bb65ffa47b52","modified":1493654168941},{"_id":"public/en/archives/2017/04/index.html","hash":"3e78408fe08c112b546db265751ab2ec18cd65b3","modified":1493654168942},{"_id":"public/index.html","hash":"e3e8d7527ae8dda6e7833d525696aeb1c2db892d","modified":1493654168942},{"_id":"public/tags/variancia/index.html","hash":"c4ed7bcdb2a93d62455e1c4b2f217de2041ba6cc","modified":1493654168942},{"_id":"public/tags/estatistica/index.html","hash":"2c05ef926794fb8ff6f0740a05459cec2cfc9549","modified":1493654168942},{"_id":"public/tags/statistics/index.html","hash":"723c7802eae0f199ac83fd064d559036af2ce004","modified":1493654168942},{"_id":"public/tags/variance/index.html","hash":"38b1fa78b8c42424d0ca5f5e75ea733825389662","modified":1493654168942},{"_id":"public/img/favicon.ico","hash":"bd8b366560b8b47d3d6b5113b40986852f8b03b9","modified":1493654168944},{"_id":"public/css/article.css","hash":"0a82c14e400156661c36c1933a1e90eee741752e","modified":1493654169553},{"_id":"public/css/mixins.css","hash":"db2b1b23abf8ce1b1e16d771013d410a346299b3","modified":1493654169553},{"_id":"public/css/base.css","hash":"4252ea3fe18351b6b7ddd8a851aba14f690ecef6","modified":1493654169554},{"_id":"public/css/style.css","hash":"dc7033967fb26078c71d0b704fb334de9f8998de","modified":1493654169554},{"_id":"public/css/variables.css","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1493654169554},{"_id":"public/img/debug.log","hash":"b359d270fa6a909eb82fa163d7165892bf4a653e","modified":1493654169583}],"Category":[],"Data":[],"Page":[],"Post":[{"title":"How to post","date":"2017-03-18T01:51:42.000Z","desc":"Como apresentar um post em markdown.","cover":"/img/ggplot.png","_content":"\n# Cria um texto cabeçalho\n\n\ntexto simple seguido de um codigo em R:\n\n```R\n   myString <- \"Hello, World!\"\n   print ( myString)\n```\n\nmais informações sobre mark down: [link](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet)\n\n> lamfo é demais\n","source":"_drafts/teste-R.md","raw":"---\ntitle: How to post\ndate: 2017-03-17 22:51:42\ntags: [\"R\", \"deeplearning\"]\ndesc: Como apresentar um post em markdown.\ncover: /img/ggplot.png\n---\n\n# Cria um texto cabeçalho\n\n\ntexto simple seguido de um codigo em R:\n\n```R\n   myString <- \"Hello, World!\"\n   print ( myString)\n```\n\nmais informações sobre mark down: [link](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet)\n\n> lamfo é demais\n","slug":"teste-R","published":0,"updated":"2017-04-30T02:30:35.092Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj26b3ttw0000y9dkiavtd1lh","content":"<h1 id=\"Cria-um-texto-cabecalho\"><a href=\"#Cria-um-texto-cabecalho\" class=\"headerlink\" title=\"Cria um texto cabeçalho\"></a>Cria um texto cabeçalho</h1><p>texto simple seguido de um codigo em R:</p><figure class=\"highlight r\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">myString &lt;- <span class=\"string\">\"Hello, World!\"</span></div><div class=\"line\">print ( myString)</div></pre></td></tr></table></figure><p>mais informações sobre mark down: <a href=\"https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet\" target=\"_blank\" rel=\"external\">link</a></p><blockquote><p>lamfo é demais</p></blockquote>","excerpt":"","more":"<h1 id=\"Cria-um-texto-cabecalho\"><a href=\"#Cria-um-texto-cabecalho\" class=\"headerlink\" title=\"Cria um texto cabeçalho\"></a>Cria um texto cabeçalho</h1><p>texto simple seguido de um codigo em R:</p><figure class=\"highlight r\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">myString &lt;- <span class=\"string\">\"Hello, World!\"</span></div><div class=\"line\">print ( myString)</div></pre></td></tr></table></figure><p>mais informações sobre mark down: <a href=\"https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet\">link</a></p><blockquote><p>lamfo é demais</p></blockquote>"},{"title":"Um Olhar Descontraído Sobre o Dilema Viés-Variância","date":"2017-04-30T02:01:56.000Z","author":"Peng Yaohao","cover":"/img/0026.png","lang":"pt","_content":"\n# Um Olhar Descontraído Sobre o Dilema Viés-Variância\n\nFazer previsões é uma das principais ambições do ser humano. Uma pessoa pode ter a motivação de saber prever quase qualquer coisa, desde o placar de um evento esportivo até o preço de uma ação ou o humor da sua namorada... Mas o futuro é uma variável aleatória -- ninguém sabe de fato como vai ser, qualquer previsão é em essência um \"chute\". Bem, como chutar então? Você pode simplesmente jogar uma moeda, isso é bem conveniente, mas certamente não dá o melhor chute possível. É aí que entra a estatística, uma área do conhecimento que defino sucintamente como \"a ciência do chute\".\n\nEnquanto o futuro é um inerente mistério, o passado é um ambiente onde não há mais incerteza, então nada mais natural e sensato que tentar prever o futuro com base no que já aconteceu. A grosso modo, com base em potenciais elementos (uma lista de $x_1,x_2,...,x_k$ variáveis independentes) que influenciem essa variável que se deseja prever (uma variável dependente $y$), tentar chutar valores futuros de $y$ ao se coletar novos valores dos $x$'s (em aprendizado de máquina, o jargão para isso é \"aprendizagem supervisionada\"). Ou seja, a estatística busca fornecer o melhor chute, condicionado às informações disponíveis.\n\nPense intuitivamente: por mais que o futuro possa trazer uma coisa completamente diferente de tudo que já foi visto, é razoável assumir que o futuro e o passado compartilham de certos **padrões**, conexões que fazem as duas instâncias temporais serem manifestações de um mesmo fenômeno. Para obter bons chutes, um conceito bem importante é o chamado **dilema viés-variância**.\n\n#### O que isso quer dizer?\n\nVamos discutir primeiro o \"viés\". É fácil imaginar que, para ser capaz de prever com exatidão o futuro, primeiro é preciso entender bem o passado. Um preditor que não consegue mapear bem as características daquilo que já se observou claramente tende a não se sair bem para o futuro. O que aqui chamamos de \"viés\" são os desvios entre aquilo que se observou no passado e aquilo que se prevê pelo modelo proposto -- em suma, é o quão bem o modelo está **descrevendo** os dados observados.\n\n![alt text](/img/chunk-8.png \"Distribuições\")\n\nÉ natural pensar que quanto melhor o modelo descreve os dados da amostra, melhor ele é. Porém, isso não é verdade, pois o objetivo primordial **não** é descrever os dados, mas usá-los para fazer previsões (ou **inferências**) sobre o futuro. Isso nos leva para o lado da \"variância\":\n\nO objetivo aqui é conseguir prever a variável de interesse com base em **alguns** elementos. De cara temos um problema, pois aquilo que efetivamente vemos é apenas uma parte do fenômeno todo; então, se nos atermos demais a simplesmente descrever os dados disponíveis, estamos no fundo torcendo para que o **mesmo padrão observado se repita para o futuro**, o que claramente não é verdade. Para poder **generalizar** o que se observou para amostras futuras -- ou seja, antecipar alguma coisa que ainda não aconteceu -- é preciso calibrar o modelo de modo a capturar apenas o \"essencial\", informações que realmente contribuem para uma boa previsão, em vez de captar por completo os padrões daquela amostra específica, pois ao fazer isso, informações inúteis (\"**ruído**\") acabam sendo incorporadas ao mesmo tempo. Basicamente, ao forçar uma descrição muito fiel dos dados da amostra, acaba que se perde em capacidade de generalização, pois o futuro em geral **não** é uma extensão do passado.\n\nModelos que descrevem excessivamente bem os dados de uma amostra tendem a introduzir muita complexidade e volatilidade, de modo a prejudicar a capacidade de generalização. Na filosofia da ciência há um princípio chamado \"navalha de Occam\", os estatísticos conhecem como \"princípio da parcimônia\"; a cultura popular adotou um mnemômico um tanto quanto ácido:\n> _\"KISS -- **keep it simple, stupid**\"_\n\nBasicamente, quer dizer que entre modelos com mesmo poder explicativo, o mais simples deles é o melhor, pois apresenta a mesma qualidade com um custo menor.\n\nA essa altura, você já deve ter percebido que estamos diante de um cobertor curto, pois o cenário ideal que buscamos possui as duas características desejáveis, porém contraditórias: queremos um modelo que descreva bem os dados disponíveis **E** que seja capaz de generalizar para dados futuros. Se temos um modelo que se ajusta mal aos dados do passado (\"under-fitting\"), o modelo já começa com pouca confiabilidade, pois não está sendo fiel às informações disponíveis; por outro lado, um ajustamento excessivo (\"over-fitting\") acaba assumindo que o futuro irá repetir o passado, de modo que o modelo tende a fornecer uma péssima previsão para observações que sejam apenas um pouquinho fora daquele padrão dos dados passados.\n\nO dilema viés-variância é muito importante na construção de modelos matemáticos: a qualidade de um modelo depende diretamente das variáveis consideradas, e saber achar o meio-termo entre incorporar variáveis úteis e descartar variáveis inúteis pode ser um desafio e tanto. Vejamos um exemplo simplista: suponha que queremos construir um modelo para prever o preço de uma ação de uma empresa. É de se esperar que o desempenho econômico da empresa tenha uma influência decisiva no preço da ação, então podemos colocar como variáveis alguns indicadores como índice de lucratividade e liquidez, o **market share** da empresa, número de filiais, e por aí vai.\n\nPoderíamos colocar por exemplo \"escolaridade do CEO\" como uma variável explicativa; é de se esperar que um gestor com uma formação acadêmica mais robusta possa incrementar o valor da companhia, mas a relação já não parece tão direta assim... Poderíamos colocar como variável se o CEO da empresa é destro, canhoto ou ambidestro, mas essa informação tende a não influenciar em nada na variável que se deseja prever, e a introdução dessa variável acabaria poluindo o modelo com uma **complexidade desnecessária**.\n\nNote que não há limites para a criatividade do pesquisador, e teoricamente poderíamos colocar um número gigantesco de variáveis. Mas à medida que variáveis com menor relevância vão sendo inseridas, chega um momento em que a \"variância\" introduzida pela nova variável não compensa o **poder explicativo** que ela agrega ao modelo.\n\nSaber encontrar o meio-termo ideal entre viés e variância não é uma tarefa fácil, há diversas técnicas para nos ajudar com isso, tais como validação cruzada e redução de dimensionalidade, podemos abordar esses tópicos em posts futuros.\n","source":"_posts/Um-Olhar-Descontraido-Sobre-o-Dilema-Vies-Variancia.md","raw":"---\ntitle: Um Olhar Descontraído Sobre o Dilema Viés-Variância\ndate: 2017-04-29 23:01:56\ntags: [variancia, estatistica]\nauthor: Peng Yaohao\ncover: /img/0026.png\nlang: pt\n---\n\n# Um Olhar Descontraído Sobre o Dilema Viés-Variância\n\nFazer previsões é uma das principais ambições do ser humano. Uma pessoa pode ter a motivação de saber prever quase qualquer coisa, desde o placar de um evento esportivo até o preço de uma ação ou o humor da sua namorada... Mas o futuro é uma variável aleatória -- ninguém sabe de fato como vai ser, qualquer previsão é em essência um \"chute\". Bem, como chutar então? Você pode simplesmente jogar uma moeda, isso é bem conveniente, mas certamente não dá o melhor chute possível. É aí que entra a estatística, uma área do conhecimento que defino sucintamente como \"a ciência do chute\".\n\nEnquanto o futuro é um inerente mistério, o passado é um ambiente onde não há mais incerteza, então nada mais natural e sensato que tentar prever o futuro com base no que já aconteceu. A grosso modo, com base em potenciais elementos (uma lista de $x_1,x_2,...,x_k$ variáveis independentes) que influenciem essa variável que se deseja prever (uma variável dependente $y$), tentar chutar valores futuros de $y$ ao se coletar novos valores dos $x$'s (em aprendizado de máquina, o jargão para isso é \"aprendizagem supervisionada\"). Ou seja, a estatística busca fornecer o melhor chute, condicionado às informações disponíveis.\n\nPense intuitivamente: por mais que o futuro possa trazer uma coisa completamente diferente de tudo que já foi visto, é razoável assumir que o futuro e o passado compartilham de certos **padrões**, conexões que fazem as duas instâncias temporais serem manifestações de um mesmo fenômeno. Para obter bons chutes, um conceito bem importante é o chamado **dilema viés-variância**.\n\n#### O que isso quer dizer?\n\nVamos discutir primeiro o \"viés\". É fácil imaginar que, para ser capaz de prever com exatidão o futuro, primeiro é preciso entender bem o passado. Um preditor que não consegue mapear bem as características daquilo que já se observou claramente tende a não se sair bem para o futuro. O que aqui chamamos de \"viés\" são os desvios entre aquilo que se observou no passado e aquilo que se prevê pelo modelo proposto -- em suma, é o quão bem o modelo está **descrevendo** os dados observados.\n\n![alt text](/img/chunk-8.png \"Distribuições\")\n\nÉ natural pensar que quanto melhor o modelo descreve os dados da amostra, melhor ele é. Porém, isso não é verdade, pois o objetivo primordial **não** é descrever os dados, mas usá-los para fazer previsões (ou **inferências**) sobre o futuro. Isso nos leva para o lado da \"variância\":\n\nO objetivo aqui é conseguir prever a variável de interesse com base em **alguns** elementos. De cara temos um problema, pois aquilo que efetivamente vemos é apenas uma parte do fenômeno todo; então, se nos atermos demais a simplesmente descrever os dados disponíveis, estamos no fundo torcendo para que o **mesmo padrão observado se repita para o futuro**, o que claramente não é verdade. Para poder **generalizar** o que se observou para amostras futuras -- ou seja, antecipar alguma coisa que ainda não aconteceu -- é preciso calibrar o modelo de modo a capturar apenas o \"essencial\", informações que realmente contribuem para uma boa previsão, em vez de captar por completo os padrões daquela amostra específica, pois ao fazer isso, informações inúteis (\"**ruído**\") acabam sendo incorporadas ao mesmo tempo. Basicamente, ao forçar uma descrição muito fiel dos dados da amostra, acaba que se perde em capacidade de generalização, pois o futuro em geral **não** é uma extensão do passado.\n\nModelos que descrevem excessivamente bem os dados de uma amostra tendem a introduzir muita complexidade e volatilidade, de modo a prejudicar a capacidade de generalização. Na filosofia da ciência há um princípio chamado \"navalha de Occam\", os estatísticos conhecem como \"princípio da parcimônia\"; a cultura popular adotou um mnemômico um tanto quanto ácido:\n> _\"KISS -- **keep it simple, stupid**\"_\n\nBasicamente, quer dizer que entre modelos com mesmo poder explicativo, o mais simples deles é o melhor, pois apresenta a mesma qualidade com um custo menor.\n\nA essa altura, você já deve ter percebido que estamos diante de um cobertor curto, pois o cenário ideal que buscamos possui as duas características desejáveis, porém contraditórias: queremos um modelo que descreva bem os dados disponíveis **E** que seja capaz de generalizar para dados futuros. Se temos um modelo que se ajusta mal aos dados do passado (\"under-fitting\"), o modelo já começa com pouca confiabilidade, pois não está sendo fiel às informações disponíveis; por outro lado, um ajustamento excessivo (\"over-fitting\") acaba assumindo que o futuro irá repetir o passado, de modo que o modelo tende a fornecer uma péssima previsão para observações que sejam apenas um pouquinho fora daquele padrão dos dados passados.\n\nO dilema viés-variância é muito importante na construção de modelos matemáticos: a qualidade de um modelo depende diretamente das variáveis consideradas, e saber achar o meio-termo entre incorporar variáveis úteis e descartar variáveis inúteis pode ser um desafio e tanto. Vejamos um exemplo simplista: suponha que queremos construir um modelo para prever o preço de uma ação de uma empresa. É de se esperar que o desempenho econômico da empresa tenha uma influência decisiva no preço da ação, então podemos colocar como variáveis alguns indicadores como índice de lucratividade e liquidez, o **market share** da empresa, número de filiais, e por aí vai.\n\nPoderíamos colocar por exemplo \"escolaridade do CEO\" como uma variável explicativa; é de se esperar que um gestor com uma formação acadêmica mais robusta possa incrementar o valor da companhia, mas a relação já não parece tão direta assim... Poderíamos colocar como variável se o CEO da empresa é destro, canhoto ou ambidestro, mas essa informação tende a não influenciar em nada na variável que se deseja prever, e a introdução dessa variável acabaria poluindo o modelo com uma **complexidade desnecessária**.\n\nNote que não há limites para a criatividade do pesquisador, e teoricamente poderíamos colocar um número gigantesco de variáveis. Mas à medida que variáveis com menor relevância vão sendo inseridas, chega um momento em que a \"variância\" introduzida pela nova variável não compensa o **poder explicativo** que ela agrega ao modelo.\n\nSaber encontrar o meio-termo ideal entre viés e variância não é uma tarefa fácil, há diversas técnicas para nos ajudar com isso, tais como validação cruzada e redução de dimensionalidade, podemos abordar esses tópicos em posts futuros.\n","slug":"Um-Olhar-Descontraido-Sobre-o-Dilema-Vies-Variancia","published":1,"updated":"2017-04-30T15:12:32.878Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj26b3tu10001y9dkyb3e8qh2","content":"<h1 id=\"Um-Olhar-Descontraido-Sobre-o-Dilema-Vies-Variancia\"><a href=\"#Um-Olhar-Descontraido-Sobre-o-Dilema-Vies-Variancia\" class=\"headerlink\" title=\"Um Olhar Descontraído Sobre o Dilema Viés-Variância\"></a>Um Olhar Descontraído Sobre o Dilema Viés-Variância</h1><p>Fazer previsões é uma das principais ambições do ser humano. Uma pessoa pode ter a motivação de saber prever quase qualquer coisa, desde o placar de um evento esportivo até o preço de uma ação ou o humor da sua namorada… Mas o futuro é uma variável aleatória – ninguém sabe de fato como vai ser, qualquer previsão é em essência um “chute”. Bem, como chutar então? Você pode simplesmente jogar uma moeda, isso é bem conveniente, mas certamente não dá o melhor chute possível. É aí que entra a estatística, uma área do conhecimento que defino sucintamente como “a ciência do chute”.</p><p>Enquanto o futuro é um inerente mistério, o passado é um ambiente onde não há mais incerteza, então nada mais natural e sensato que tentar prever o futuro com base no que já aconteceu. A grosso modo, com base em potenciais elementos (uma lista de $x_1,x_2,…,x_k$ variáveis independentes) que influenciem essa variável que se deseja prever (uma variável dependente $y$), tentar chutar valores futuros de $y$ ao se coletar novos valores dos $x$’s (em aprendizado de máquina, o jargão para isso é “aprendizagem supervisionada”). Ou seja, a estatística busca fornecer o melhor chute, condicionado às informações disponíveis.</p><p>Pense intuitivamente: por mais que o futuro possa trazer uma coisa completamente diferente de tudo que já foi visto, é razoável assumir que o futuro e o passado compartilham de certos <strong>padrões</strong>, conexões que fazem as duas instâncias temporais serem manifestações de um mesmo fenômeno. Para obter bons chutes, um conceito bem importante é o chamado <strong>dilema viés-variância</strong>.</p><h4 id=\"O-que-isso-quer-dizer\"><a href=\"#O-que-isso-quer-dizer\" class=\"headerlink\" title=\"O que isso quer dizer?\"></a>O que isso quer dizer?</h4><p>Vamos discutir primeiro o “viés”. É fácil imaginar que, para ser capaz de prever com exatidão o futuro, primeiro é preciso entender bem o passado. Um preditor que não consegue mapear bem as características daquilo que já se observou claramente tende a não se sair bem para o futuro. O que aqui chamamos de “viés” são os desvios entre aquilo que se observou no passado e aquilo que se prevê pelo modelo proposto – em suma, é o quão bem o modelo está <strong>descrevendo</strong> os dados observados.</p><p><img src=\"/img/chunk-8.png\" alt=\"alt text\" title=\"Distribuições\"></p><p>É natural pensar que quanto melhor o modelo descreve os dados da amostra, melhor ele é. Porém, isso não é verdade, pois o objetivo primordial <strong>não</strong> é descrever os dados, mas usá-los para fazer previsões (ou <strong>inferências</strong>) sobre o futuro. Isso nos leva para o lado da “variância”:</p><p>O objetivo aqui é conseguir prever a variável de interesse com base em <strong>alguns</strong> elementos. De cara temos um problema, pois aquilo que efetivamente vemos é apenas uma parte do fenômeno todo; então, se nos atermos demais a simplesmente descrever os dados disponíveis, estamos no fundo torcendo para que o <strong>mesmo padrão observado se repita para o futuro</strong>, o que claramente não é verdade. Para poder <strong>generalizar</strong> o que se observou para amostras futuras – ou seja, antecipar alguma coisa que ainda não aconteceu – é preciso calibrar o modelo de modo a capturar apenas o “essencial”, informações que realmente contribuem para uma boa previsão, em vez de captar por completo os padrões daquela amostra específica, pois ao fazer isso, informações inúteis (“<strong>ruído</strong>“) acabam sendo incorporadas ao mesmo tempo. Basicamente, ao forçar uma descrição muito fiel dos dados da amostra, acaba que se perde em capacidade de generalização, pois o futuro em geral <strong>não</strong> é uma extensão do passado.</p><p>Modelos que descrevem excessivamente bem os dados de uma amostra tendem a introduzir muita complexidade e volatilidade, de modo a prejudicar a capacidade de generalização. Na filosofia da ciência há um princípio chamado “navalha de Occam”, os estatísticos conhecem como “princípio da parcimônia”; a cultura popular adotou um mnemômico um tanto quanto ácido:</p><blockquote><p><em>“KISS – <strong>keep it simple, stupid</strong>“</em></p></blockquote><p>Basicamente, quer dizer que entre modelos com mesmo poder explicativo, o mais simples deles é o melhor, pois apresenta a mesma qualidade com um custo menor.</p><p>A essa altura, você já deve ter percebido que estamos diante de um cobertor curto, pois o cenário ideal que buscamos possui as duas características desejáveis, porém contraditórias: queremos um modelo que descreva bem os dados disponíveis <strong>E</strong> que seja capaz de generalizar para dados futuros. Se temos um modelo que se ajusta mal aos dados do passado (“under-fitting”), o modelo já começa com pouca confiabilidade, pois não está sendo fiel às informações disponíveis; por outro lado, um ajustamento excessivo (“over-fitting”) acaba assumindo que o futuro irá repetir o passado, de modo que o modelo tende a fornecer uma péssima previsão para observações que sejam apenas um pouquinho fora daquele padrão dos dados passados.</p><p>O dilema viés-variância é muito importante na construção de modelos matemáticos: a qualidade de um modelo depende diretamente das variáveis consideradas, e saber achar o meio-termo entre incorporar variáveis úteis e descartar variáveis inúteis pode ser um desafio e tanto. Vejamos um exemplo simplista: suponha que queremos construir um modelo para prever o preço de uma ação de uma empresa. É de se esperar que o desempenho econômico da empresa tenha uma influência decisiva no preço da ação, então podemos colocar como variáveis alguns indicadores como índice de lucratividade e liquidez, o <strong>market share</strong> da empresa, número de filiais, e por aí vai.</p><p>Poderíamos colocar por exemplo “escolaridade do CEO” como uma variável explicativa; é de se esperar que um gestor com uma formação acadêmica mais robusta possa incrementar o valor da companhia, mas a relação já não parece tão direta assim… Poderíamos colocar como variável se o CEO da empresa é destro, canhoto ou ambidestro, mas essa informação tende a não influenciar em nada na variável que se deseja prever, e a introdução dessa variável acabaria poluindo o modelo com uma <strong>complexidade desnecessária</strong>.</p><p>Note que não há limites para a criatividade do pesquisador, e teoricamente poderíamos colocar um número gigantesco de variáveis. Mas à medida que variáveis com menor relevância vão sendo inseridas, chega um momento em que a “variância” introduzida pela nova variável não compensa o <strong>poder explicativo</strong> que ela agrega ao modelo.</p><p>Saber encontrar o meio-termo ideal entre viés e variância não é uma tarefa fácil, há diversas técnicas para nos ajudar com isso, tais como validação cruzada e redução de dimensionalidade, podemos abordar esses tópicos em posts futuros.</p>","excerpt":"","more":"<h1 id=\"Um-Olhar-Descontraido-Sobre-o-Dilema-Vies-Variancia\"><a href=\"#Um-Olhar-Descontraido-Sobre-o-Dilema-Vies-Variancia\" class=\"headerlink\" title=\"Um Olhar Descontraído Sobre o Dilema Viés-Variância\"></a>Um Olhar Descontraído Sobre o Dilema Viés-Variância</h1><p>Fazer previsões é uma das principais ambições do ser humano. Uma pessoa pode ter a motivação de saber prever quase qualquer coisa, desde o placar de um evento esportivo até o preço de uma ação ou o humor da sua namorada… Mas o futuro é uma variável aleatória – ninguém sabe de fato como vai ser, qualquer previsão é em essência um “chute”. Bem, como chutar então? Você pode simplesmente jogar uma moeda, isso é bem conveniente, mas certamente não dá o melhor chute possível. É aí que entra a estatística, uma área do conhecimento que defino sucintamente como “a ciência do chute”.</p><p>Enquanto o futuro é um inerente mistério, o passado é um ambiente onde não há mais incerteza, então nada mais natural e sensato que tentar prever o futuro com base no que já aconteceu. A grosso modo, com base em potenciais elementos (uma lista de $x_1,x_2,…,x_k$ variáveis independentes) que influenciem essa variável que se deseja prever (uma variável dependente $y$), tentar chutar valores futuros de $y$ ao se coletar novos valores dos $x$’s (em aprendizado de máquina, o jargão para isso é “aprendizagem supervisionada”). Ou seja, a estatística busca fornecer o melhor chute, condicionado às informações disponíveis.</p><p>Pense intuitivamente: por mais que o futuro possa trazer uma coisa completamente diferente de tudo que já foi visto, é razoável assumir que o futuro e o passado compartilham de certos <strong>padrões</strong>, conexões que fazem as duas instâncias temporais serem manifestações de um mesmo fenômeno. Para obter bons chutes, um conceito bem importante é o chamado <strong>dilema viés-variância</strong>.</p><h4 id=\"O-que-isso-quer-dizer\"><a href=\"#O-que-isso-quer-dizer\" class=\"headerlink\" title=\"O que isso quer dizer?\"></a>O que isso quer dizer?</h4><p>Vamos discutir primeiro o “viés”. É fácil imaginar que, para ser capaz de prever com exatidão o futuro, primeiro é preciso entender bem o passado. Um preditor que não consegue mapear bem as características daquilo que já se observou claramente tende a não se sair bem para o futuro. O que aqui chamamos de “viés” são os desvios entre aquilo que se observou no passado e aquilo que se prevê pelo modelo proposto – em suma, é o quão bem o modelo está <strong>descrevendo</strong> os dados observados.</p><p><img src=\"/img/chunk-8.png\" alt=\"alt text\" title=\"Distribuições\"></p><p>É natural pensar que quanto melhor o modelo descreve os dados da amostra, melhor ele é. Porém, isso não é verdade, pois o objetivo primordial <strong>não</strong> é descrever os dados, mas usá-los para fazer previsões (ou <strong>inferências</strong>) sobre o futuro. Isso nos leva para o lado da “variância”:</p><p>O objetivo aqui é conseguir prever a variável de interesse com base em <strong>alguns</strong> elementos. De cara temos um problema, pois aquilo que efetivamente vemos é apenas uma parte do fenômeno todo; então, se nos atermos demais a simplesmente descrever os dados disponíveis, estamos no fundo torcendo para que o <strong>mesmo padrão observado se repita para o futuro</strong>, o que claramente não é verdade. Para poder <strong>generalizar</strong> o que se observou para amostras futuras – ou seja, antecipar alguma coisa que ainda não aconteceu – é preciso calibrar o modelo de modo a capturar apenas o “essencial”, informações que realmente contribuem para uma boa previsão, em vez de captar por completo os padrões daquela amostra específica, pois ao fazer isso, informações inúteis (“<strong>ruído</strong>“) acabam sendo incorporadas ao mesmo tempo. Basicamente, ao forçar uma descrição muito fiel dos dados da amostra, acaba que se perde em capacidade de generalização, pois o futuro em geral <strong>não</strong> é uma extensão do passado.</p><p>Modelos que descrevem excessivamente bem os dados de uma amostra tendem a introduzir muita complexidade e volatilidade, de modo a prejudicar a capacidade de generalização. Na filosofia da ciência há um princípio chamado “navalha de Occam”, os estatísticos conhecem como “princípio da parcimônia”; a cultura popular adotou um mnemômico um tanto quanto ácido:</p><blockquote><p><em>“KISS – <strong>keep it simple, stupid</strong>“</em></p></blockquote><p>Basicamente, quer dizer que entre modelos com mesmo poder explicativo, o mais simples deles é o melhor, pois apresenta a mesma qualidade com um custo menor.</p><p>A essa altura, você já deve ter percebido que estamos diante de um cobertor curto, pois o cenário ideal que buscamos possui as duas características desejáveis, porém contraditórias: queremos um modelo que descreva bem os dados disponíveis <strong>E</strong> que seja capaz de generalizar para dados futuros. Se temos um modelo que se ajusta mal aos dados do passado (“under-fitting”), o modelo já começa com pouca confiabilidade, pois não está sendo fiel às informações disponíveis; por outro lado, um ajustamento excessivo (“over-fitting”) acaba assumindo que o futuro irá repetir o passado, de modo que o modelo tende a fornecer uma péssima previsão para observações que sejam apenas um pouquinho fora daquele padrão dos dados passados.</p><p>O dilema viés-variância é muito importante na construção de modelos matemáticos: a qualidade de um modelo depende diretamente das variáveis consideradas, e saber achar o meio-termo entre incorporar variáveis úteis e descartar variáveis inúteis pode ser um desafio e tanto. Vejamos um exemplo simplista: suponha que queremos construir um modelo para prever o preço de uma ação de uma empresa. É de se esperar que o desempenho econômico da empresa tenha uma influência decisiva no preço da ação, então podemos colocar como variáveis alguns indicadores como índice de lucratividade e liquidez, o <strong>market share</strong> da empresa, número de filiais, e por aí vai.</p><p>Poderíamos colocar por exemplo “escolaridade do CEO” como uma variável explicativa; é de se esperar que um gestor com uma formação acadêmica mais robusta possa incrementar o valor da companhia, mas a relação já não parece tão direta assim… Poderíamos colocar como variável se o CEO da empresa é destro, canhoto ou ambidestro, mas essa informação tende a não influenciar em nada na variável que se deseja prever, e a introdução dessa variável acabaria poluindo o modelo com uma <strong>complexidade desnecessária</strong>.</p><p>Note que não há limites para a criatividade do pesquisador, e teoricamente poderíamos colocar um número gigantesco de variáveis. Mas à medida que variáveis com menor relevância vão sendo inseridas, chega um momento em que a “variância” introduzida pela nova variável não compensa o <strong>poder explicativo</strong> que ela agrega ao modelo.</p><p>Saber encontrar o meio-termo ideal entre viés e variância não é uma tarefa fácil, há diversas técnicas para nos ajudar com isso, tais como validação cruzada e redução de dimensionalidade, podemos abordar esses tópicos em posts futuros.</p>"},{"title":"A Casual Look at the Bias-Variance Dilemma","lang":"en","cover":"/img/0026.png","date":"2017-04-30T02:59:07.000Z","author":"Peng Yaohao","_content":"\n# A Casual Look at the Bias-Variance Dilemma\n\nMaking predictions is one of the main ambitions of the human race. One may have the motivation to forecast almost anything from a sports event to the stock price or his girlfriend's mood... But the future is a random variable -- no one really knows how it's gonna be, so any prediction is in essence a \"guess\". Well, how to guess then? You can simply toss a coin, this is quite convenient, but it certainly does not give the best guess possible. This is where statistics comes to stage, as I define briefly that knowledge field as \"the science of guessing\".\n\nWhile the future is an inherent mystery, the past is an environment where uncertainty doesn't exist anymore, so it's only natural and reasonable trying to predict the future based on what has already happened. Roughly, based on elements (a list of $x_1,x_2,...,x_k$ independent variables) that may have influence on the variable to be predicted (a dependent variable $y$), the goal is to try and guess future values of $y$ by collecting new values of the $x$s (in machine learning, the jargon for this is \"supervised learning\"). That is, statistics seek to provide the best guess, conditioned to the available information.\n\nThink intuitively: even though the future may bring in stuff completely different from anything seen in the past, it's reasonable to assume that both future and past share certain **patterns**, connections that make those two temporal instances a manifestation of the same phenomenon. To get good guesses, a very important concept is called **bias-variance dilemma**.\n\n#### What does it mean exactly?\n\nLet's first discuss \"bias\". It's easy to imagine that in order to accurately predict the future, one must first understand the past well. A predictor that fails to map clearly the characteristics of clearly observed data tends not perform badly for the future. What we call \"bias\" are the deviations between the observed in the past and the predicted by the proposed model -- in short, how well the model is **describing** the observed data.\n\n![alt text](/img/chunk-8.png \"Distribution\")\n\nIt is natural to think that the better the model describes the sample data, the better it is. But this is not true, since the primary purpose is **not** to describe the data, but rather to use those to make predictions (or **inferences**) about the future. This brings us to the \"variance\" side:\n\nOur goal here is to be able to predict the variable of interest $y$ based on **some** elements of the whole population, so we have a major problem from the start, for what we actually see in the sample is only part of the whole phenomenon; so if we simply stick onto describing the already available data, we essencially **hoping that the same pattern will repeat in the future**, which clearly doesn't always happens. To be able to **generalize** what has been observed for future samples -- that is, to anticipate something that has not yet happened -- one must calibrate the model for it to capture only the \"essential\" information that actually contributes to a good prediction, instead of fully capturing the patterns of that particular sample, because in doing so, useless information (\"**noise**\") is incorporated at the same time. Basically, by forcing a very accurate description of the sample data, we end up losing in generalization ability, since, in general, the future is **not** a mere extension of the past.\n\nModels that describe the data of a sample excessively well tend to introduce a lot of complexity and volatility, thus hindering the generalization ability. In the philosophy of science there is a principle called **Occam's razor** (the statisticians know it as the \"principle of parsimony\", popular culture has adopted a rather pushy mnemonic: \n> _\"KISS -- **keep it simple, stupid**\"_\n\nBasically, it means that between models with the same explanatory power, the simplest of them is the best, because it presents the same quality with a lower cost.\n\nBy now, you should have realized that we indeed face a dilemma, as the ideal scenario demands two desirable but contradictory features: we want a model that describes well the available data **AND** is capable of generalizing for future data. If we fit a model that misrepresents past data (\"under-fitting\"), the model is kinda unreliable from the start. On the other hand, an over-adjustment (\"over-fitting\") ends up assuming that the future will repeat the past, so the model tends to provide a poor prediction even for observations that follow just slightly different trends than the one showed in past data.\n\nThe bias-variance dilemma is very important in the mathematical modelling: the quality of a model depends directly on the variables considered, and the optimal middle ground between incorporating useful variables and discarding useless variables can be quite a challenge. Let's look at a simple example: Suppose that we want to construct a model to predict a company's stock price. Is to be expected that the economic performance of that company influences decisively on the stock price, so we can put as variables some indicators like index of profitability and liquidity, the company's market share, number of subsidiaries, and so on.\n\nFor instance, we could put \"CEO's scholarity\" as an explanatory variable; It is to be expected that a manager with a more robust academic background can increase the value of the company, but the relationship doesn't seem that straightforward... We could insert as a variable whether the CEO is right-handed, left-handed or ambidextrous, but this information tends not to influence the predicted variable at all, and the introduction of this variable would end up polluting the model with an **unnecessary complexity**.\n\nNote that there're no limits to the researcher's creativity, and theoretically we could put a gigantic number of variables. But as less relevant variables are inserted, there comes a time when the \"variance\" introduced by the new variable does not compensate for the **explanatory power** that it adds to the model.\n\nKnowing how to find the ideal middle ground between bias and variance is not an easy task, there are several techniques to aid us with this, such as cross-validation and dimensionality reduction, we can address these topics in future posts.\n","source":"_posts/A-Casual-Look-at-the-Bias-Variance-Dilemma.md","raw":"---\ntitle: A Casual Look at the Bias-Variance Dilemma\nlang: en\ncover: /img/0026.png\ndate: 2017-04-29 23:59:07\ntags: [statistics,variance]\nauthor: Peng Yaohao\n---\n\n# A Casual Look at the Bias-Variance Dilemma\n\nMaking predictions is one of the main ambitions of the human race. One may have the motivation to forecast almost anything from a sports event to the stock price or his girlfriend's mood... But the future is a random variable -- no one really knows how it's gonna be, so any prediction is in essence a \"guess\". Well, how to guess then? You can simply toss a coin, this is quite convenient, but it certainly does not give the best guess possible. This is where statistics comes to stage, as I define briefly that knowledge field as \"the science of guessing\".\n\nWhile the future is an inherent mystery, the past is an environment where uncertainty doesn't exist anymore, so it's only natural and reasonable trying to predict the future based on what has already happened. Roughly, based on elements (a list of $x_1,x_2,...,x_k$ independent variables) that may have influence on the variable to be predicted (a dependent variable $y$), the goal is to try and guess future values of $y$ by collecting new values of the $x$s (in machine learning, the jargon for this is \"supervised learning\"). That is, statistics seek to provide the best guess, conditioned to the available information.\n\nThink intuitively: even though the future may bring in stuff completely different from anything seen in the past, it's reasonable to assume that both future and past share certain **patterns**, connections that make those two temporal instances a manifestation of the same phenomenon. To get good guesses, a very important concept is called **bias-variance dilemma**.\n\n#### What does it mean exactly?\n\nLet's first discuss \"bias\". It's easy to imagine that in order to accurately predict the future, one must first understand the past well. A predictor that fails to map clearly the characteristics of clearly observed data tends not perform badly for the future. What we call \"bias\" are the deviations between the observed in the past and the predicted by the proposed model -- in short, how well the model is **describing** the observed data.\n\n![alt text](/img/chunk-8.png \"Distribution\")\n\nIt is natural to think that the better the model describes the sample data, the better it is. But this is not true, since the primary purpose is **not** to describe the data, but rather to use those to make predictions (or **inferences**) about the future. This brings us to the \"variance\" side:\n\nOur goal here is to be able to predict the variable of interest $y$ based on **some** elements of the whole population, so we have a major problem from the start, for what we actually see in the sample is only part of the whole phenomenon; so if we simply stick onto describing the already available data, we essencially **hoping that the same pattern will repeat in the future**, which clearly doesn't always happens. To be able to **generalize** what has been observed for future samples -- that is, to anticipate something that has not yet happened -- one must calibrate the model for it to capture only the \"essential\" information that actually contributes to a good prediction, instead of fully capturing the patterns of that particular sample, because in doing so, useless information (\"**noise**\") is incorporated at the same time. Basically, by forcing a very accurate description of the sample data, we end up losing in generalization ability, since, in general, the future is **not** a mere extension of the past.\n\nModels that describe the data of a sample excessively well tend to introduce a lot of complexity and volatility, thus hindering the generalization ability. In the philosophy of science there is a principle called **Occam's razor** (the statisticians know it as the \"principle of parsimony\", popular culture has adopted a rather pushy mnemonic: \n> _\"KISS -- **keep it simple, stupid**\"_\n\nBasically, it means that between models with the same explanatory power, the simplest of them is the best, because it presents the same quality with a lower cost.\n\nBy now, you should have realized that we indeed face a dilemma, as the ideal scenario demands two desirable but contradictory features: we want a model that describes well the available data **AND** is capable of generalizing for future data. If we fit a model that misrepresents past data (\"under-fitting\"), the model is kinda unreliable from the start. On the other hand, an over-adjustment (\"over-fitting\") ends up assuming that the future will repeat the past, so the model tends to provide a poor prediction even for observations that follow just slightly different trends than the one showed in past data.\n\nThe bias-variance dilemma is very important in the mathematical modelling: the quality of a model depends directly on the variables considered, and the optimal middle ground between incorporating useful variables and discarding useless variables can be quite a challenge. Let's look at a simple example: Suppose that we want to construct a model to predict a company's stock price. Is to be expected that the economic performance of that company influences decisively on the stock price, so we can put as variables some indicators like index of profitability and liquidity, the company's market share, number of subsidiaries, and so on.\n\nFor instance, we could put \"CEO's scholarity\" as an explanatory variable; It is to be expected that a manager with a more robust academic background can increase the value of the company, but the relationship doesn't seem that straightforward... We could insert as a variable whether the CEO is right-handed, left-handed or ambidextrous, but this information tends not to influence the predicted variable at all, and the introduction of this variable would end up polluting the model with an **unnecessary complexity**.\n\nNote that there're no limits to the researcher's creativity, and theoretically we could put a gigantic number of variables. But as less relevant variables are inserted, there comes a time when the \"variance\" introduced by the new variable does not compensate for the **explanatory power** that it adds to the model.\n\nKnowing how to find the ideal middle ground between bias and variance is not an easy task, there are several techniques to aid us with this, such as cross-validation and dimensionality reduction, we can address these topics in future posts.\n","slug":"A-Casual-Look-at-the-Bias-Variance-Dilemma","published":1,"updated":"2017-04-30T15:18:42.148Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj26b3tu80003y9dkjw8b3bjr","content":"<h1 id=\"A-Casual-Look-at-the-Bias-Variance-Dilemma\"><a href=\"#A-Casual-Look-at-the-Bias-Variance-Dilemma\" class=\"headerlink\" title=\"A Casual Look at the Bias-Variance Dilemma\"></a>A Casual Look at the Bias-Variance Dilemma</h1><p>Making predictions is one of the main ambitions of the human race. One may have the motivation to forecast almost anything from a sports event to the stock price or his girlfriend’s mood… But the future is a random variable – no one really knows how it’s gonna be, so any prediction is in essence a “guess”. Well, how to guess then? You can simply toss a coin, this is quite convenient, but it certainly does not give the best guess possible. This is where statistics comes to stage, as I define briefly that knowledge field as “the science of guessing”.</p><p>While the future is an inherent mystery, the past is an environment where uncertainty doesn’t exist anymore, so it’s only natural and reasonable trying to predict the future based on what has already happened. Roughly, based on elements (a list of $x_1,x_2,…,x_k$ independent variables) that may have influence on the variable to be predicted (a dependent variable $y$), the goal is to try and guess future values of $y$ by collecting new values of the $x$s (in machine learning, the jargon for this is “supervised learning”). That is, statistics seek to provide the best guess, conditioned to the available information.</p><p>Think intuitively: even though the future may bring in stuff completely different from anything seen in the past, it’s reasonable to assume that both future and past share certain <strong>patterns</strong>, connections that make those two temporal instances a manifestation of the same phenomenon. To get good guesses, a very important concept is called <strong>bias-variance dilemma</strong>.</p><h4 id=\"What-does-it-mean-exactly\"><a href=\"#What-does-it-mean-exactly\" class=\"headerlink\" title=\"What does it mean exactly?\"></a>What does it mean exactly?</h4><p>Let’s first discuss “bias”. It’s easy to imagine that in order to accurately predict the future, one must first understand the past well. A predictor that fails to map clearly the characteristics of clearly observed data tends not perform badly for the future. What we call “bias” are the deviations between the observed in the past and the predicted by the proposed model – in short, how well the model is <strong>describing</strong> the observed data.</p><p><img src=\"/img/chunk-8.png\" alt=\"alt text\" title=\"Distribution\"></p><p>It is natural to think that the better the model describes the sample data, the better it is. But this is not true, since the primary purpose is <strong>not</strong> to describe the data, but rather to use those to make predictions (or <strong>inferences</strong>) about the future. This brings us to the “variance” side:</p><p>Our goal here is to be able to predict the variable of interest $y$ based on <strong>some</strong> elements of the whole population, so we have a major problem from the start, for what we actually see in the sample is only part of the whole phenomenon; so if we simply stick onto describing the already available data, we essencially <strong>hoping that the same pattern will repeat in the future</strong>, which clearly doesn’t always happens. To be able to <strong>generalize</strong> what has been observed for future samples – that is, to anticipate something that has not yet happened – one must calibrate the model for it to capture only the “essential” information that actually contributes to a good prediction, instead of fully capturing the patterns of that particular sample, because in doing so, useless information (“<strong>noise</strong>“) is incorporated at the same time. Basically, by forcing a very accurate description of the sample data, we end up losing in generalization ability, since, in general, the future is <strong>not</strong> a mere extension of the past.</p><p>Models that describe the data of a sample excessively well tend to introduce a lot of complexity and volatility, thus hindering the generalization ability. In the philosophy of science there is a principle called <strong>Occam’s razor</strong> (the statisticians know it as the “principle of parsimony”, popular culture has adopted a rather pushy mnemonic:</p><blockquote><p><em>“KISS – <strong>keep it simple, stupid</strong>“</em></p></blockquote><p>Basically, it means that between models with the same explanatory power, the simplest of them is the best, because it presents the same quality with a lower cost.</p><p>By now, you should have realized that we indeed face a dilemma, as the ideal scenario demands two desirable but contradictory features: we want a model that describes well the available data <strong>AND</strong> is capable of generalizing for future data. If we fit a model that misrepresents past data (“under-fitting”), the model is kinda unreliable from the start. On the other hand, an over-adjustment (“over-fitting”) ends up assuming that the future will repeat the past, so the model tends to provide a poor prediction even for observations that follow just slightly different trends than the one showed in past data.</p><p>The bias-variance dilemma is very important in the mathematical modelling: the quality of a model depends directly on the variables considered, and the optimal middle ground between incorporating useful variables and discarding useless variables can be quite a challenge. Let’s look at a simple example: Suppose that we want to construct a model to predict a company’s stock price. Is to be expected that the economic performance of that company influences decisively on the stock price, so we can put as variables some indicators like index of profitability and liquidity, the company’s market share, number of subsidiaries, and so on.</p><p>For instance, we could put “CEO’s scholarity” as an explanatory variable; It is to be expected that a manager with a more robust academic background can increase the value of the company, but the relationship doesn’t seem that straightforward… We could insert as a variable whether the CEO is right-handed, left-handed or ambidextrous, but this information tends not to influence the predicted variable at all, and the introduction of this variable would end up polluting the model with an <strong>unnecessary complexity</strong>.</p><p>Note that there’re no limits to the researcher’s creativity, and theoretically we could put a gigantic number of variables. But as less relevant variables are inserted, there comes a time when the “variance” introduced by the new variable does not compensate for the <strong>explanatory power</strong> that it adds to the model.</p><p>Knowing how to find the ideal middle ground between bias and variance is not an easy task, there are several techniques to aid us with this, such as cross-validation and dimensionality reduction, we can address these topics in future posts.</p>","excerpt":"","more":"<h1 id=\"A-Casual-Look-at-the-Bias-Variance-Dilemma\"><a href=\"#A-Casual-Look-at-the-Bias-Variance-Dilemma\" class=\"headerlink\" title=\"A Casual Look at the Bias-Variance Dilemma\"></a>A Casual Look at the Bias-Variance Dilemma</h1><p>Making predictions is one of the main ambitions of the human race. One may have the motivation to forecast almost anything from a sports event to the stock price or his girlfriend’s mood… But the future is a random variable – no one really knows how it’s gonna be, so any prediction is in essence a “guess”. Well, how to guess then? You can simply toss a coin, this is quite convenient, but it certainly does not give the best guess possible. This is where statistics comes to stage, as I define briefly that knowledge field as “the science of guessing”.</p><p>While the future is an inherent mystery, the past is an environment where uncertainty doesn’t exist anymore, so it’s only natural and reasonable trying to predict the future based on what has already happened. Roughly, based on elements (a list of $x_1,x_2,…,x_k$ independent variables) that may have influence on the variable to be predicted (a dependent variable $y$), the goal is to try and guess future values of $y$ by collecting new values of the $x$s (in machine learning, the jargon for this is “supervised learning”). That is, statistics seek to provide the best guess, conditioned to the available information.</p><p>Think intuitively: even though the future may bring in stuff completely different from anything seen in the past, it’s reasonable to assume that both future and past share certain <strong>patterns</strong>, connections that make those two temporal instances a manifestation of the same phenomenon. To get good guesses, a very important concept is called <strong>bias-variance dilemma</strong>.</p><h4 id=\"What-does-it-mean-exactly\"><a href=\"#What-does-it-mean-exactly\" class=\"headerlink\" title=\"What does it mean exactly?\"></a>What does it mean exactly?</h4><p>Let’s first discuss “bias”. It’s easy to imagine that in order to accurately predict the future, one must first understand the past well. A predictor that fails to map clearly the characteristics of clearly observed data tends not perform badly for the future. What we call “bias” are the deviations between the observed in the past and the predicted by the proposed model – in short, how well the model is <strong>describing</strong> the observed data.</p><p><img src=\"/img/chunk-8.png\" alt=\"alt text\" title=\"Distribution\"></p><p>It is natural to think that the better the model describes the sample data, the better it is. But this is not true, since the primary purpose is <strong>not</strong> to describe the data, but rather to use those to make predictions (or <strong>inferences</strong>) about the future. This brings us to the “variance” side:</p><p>Our goal here is to be able to predict the variable of interest $y$ based on <strong>some</strong> elements of the whole population, so we have a major problem from the start, for what we actually see in the sample is only part of the whole phenomenon; so if we simply stick onto describing the already available data, we essencially <strong>hoping that the same pattern will repeat in the future</strong>, which clearly doesn’t always happens. To be able to <strong>generalize</strong> what has been observed for future samples – that is, to anticipate something that has not yet happened – one must calibrate the model for it to capture only the “essential” information that actually contributes to a good prediction, instead of fully capturing the patterns of that particular sample, because in doing so, useless information (“<strong>noise</strong>“) is incorporated at the same time. Basically, by forcing a very accurate description of the sample data, we end up losing in generalization ability, since, in general, the future is <strong>not</strong> a mere extension of the past.</p><p>Models that describe the data of a sample excessively well tend to introduce a lot of complexity and volatility, thus hindering the generalization ability. In the philosophy of science there is a principle called <strong>Occam’s razor</strong> (the statisticians know it as the “principle of parsimony”, popular culture has adopted a rather pushy mnemonic:</p><blockquote><p><em>“KISS – <strong>keep it simple, stupid</strong>“</em></p></blockquote><p>Basically, it means that between models with the same explanatory power, the simplest of them is the best, because it presents the same quality with a lower cost.</p><p>By now, you should have realized that we indeed face a dilemma, as the ideal scenario demands two desirable but contradictory features: we want a model that describes well the available data <strong>AND</strong> is capable of generalizing for future data. If we fit a model that misrepresents past data (“under-fitting”), the model is kinda unreliable from the start. On the other hand, an over-adjustment (“over-fitting”) ends up assuming that the future will repeat the past, so the model tends to provide a poor prediction even for observations that follow just slightly different trends than the one showed in past data.</p><p>The bias-variance dilemma is very important in the mathematical modelling: the quality of a model depends directly on the variables considered, and the optimal middle ground between incorporating useful variables and discarding useless variables can be quite a challenge. Let’s look at a simple example: Suppose that we want to construct a model to predict a company’s stock price. Is to be expected that the economic performance of that company influences decisively on the stock price, so we can put as variables some indicators like index of profitability and liquidity, the company’s market share, number of subsidiaries, and so on.</p><p>For instance, we could put “CEO’s scholarity” as an explanatory variable; It is to be expected that a manager with a more robust academic background can increase the value of the company, but the relationship doesn’t seem that straightforward… We could insert as a variable whether the CEO is right-handed, left-handed or ambidextrous, but this information tends not to influence the predicted variable at all, and the introduction of this variable would end up polluting the model with an <strong>unnecessary complexity</strong>.</p><p>Note that there’re no limits to the researcher’s creativity, and theoretically we could put a gigantic number of variables. But as less relevant variables are inserted, there comes a time when the “variance” introduced by the new variable does not compensate for the <strong>explanatory power</strong> that it adds to the model.</p><p>Knowing how to find the ideal middle ground between bias and variance is not an easy task, there are several techniques to aid us with this, such as cross-validation and dimensionality reduction, we can address these topics in future posts.</p>"}],"PostAsset":[],"PostCategory":[],"PostTag":[{"post_id":"cj26b3ttw0000y9dkiavtd1lh","tag_id":"cj26b3tu60002y9dkap5vfb10","_id":"cj26b3tua0006y9dkj7r913iu"},{"post_id":"cj26b3ttw0000y9dkiavtd1lh","tag_id":"cj26b3tu90004y9dkxd6p0uia","_id":"cj26b3tua0007y9dkxvmcsni7"},{"post_id":"cj26b3tu10001y9dkyb3e8qh2","tag_id":"cj26b3tua0005y9dkbb6a5o5k","_id":"cj26b3tuc000ay9dk3lhz8ib9"},{"post_id":"cj26b3tu10001y9dkyb3e8qh2","tag_id":"cj26b3tub0008y9dk9q2uuux5","_id":"cj26b3tuc000by9dku68zoh3v"},{"post_id":"cj26b3tu80003y9dkjw8b3bjr","tag_id":"cj26b3tuc0009y9dk7f4urwit","_id":"cj26b3tuc000dy9dklgppg9wc"},{"post_id":"cj26b3tu80003y9dkjw8b3bjr","tag_id":"cj26b3tuc000cy9dkinpd12rz","_id":"cj26b3tuc000ey9dk1az79te4"}],"Tag":[{"name":"R","_id":"cj26b3tu60002y9dkap5vfb10"},{"name":"deeplearning","_id":"cj26b3tu90004y9dkxd6p0uia"},{"name":"variancia","_id":"cj26b3tua0005y9dkbb6a5o5k"},{"name":"estatistica","_id":"cj26b3tub0008y9dk9q2uuux5"},{"name":"statistics","_id":"cj26b3tuc0009y9dk7f4urwit"},{"name":"variance","_id":"cj26b3tuc000cy9dkinpd12rz"}]}}